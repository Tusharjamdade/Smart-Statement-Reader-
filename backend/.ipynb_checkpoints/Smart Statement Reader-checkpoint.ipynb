{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6aa9a5d-2224-40bb-8b8b-2ba8d48ab4d8",
   "metadata": {},
   "source": [
    "# 🌟 **Smart Statement Reader** 🚀  \n",
    "\n",
    "> **An AI/ML-powered solution for processing financial PDFs with precision and efficiency.**  \n",
    "\n",
    " 🔹 **Features:**  \n",
    "    - 📂 **Automatic File Format Detection** – Identifies PDF structures effortlessly.  \n",
    "    - 📊 **Financial Ledger Extraction** – Extracts and organizes financial data into structured formats.  \n",
    "    - 🛠️ **Handling Formatting Inconsistencies** – Adapts to varying PDF formats seamlessly.  \n",
    "    - 🎯 **Confidence Scoring** – Provides accuracy insights on extracted data.  \n",
    "    - 🔄 **User Feedback Integration** – Continuously improves through corrections and feedback.  \n",
    "\n",
    "    ✨ Transform financial statements into actionable insights with AI!  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf59751-67cb-41e1-af73-157e4aa066f2",
   "metadata": {},
   "source": [
    "#### Detect PDF Type (Structured vs. Scanned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cca44930-f297-4529-ba60-7fe8a77a1dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "\n",
    "def is_scanned_pdf(pdf_path):\n",
    "    \"\"\"Check if the PDF is scanned or structured\"\"\"\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            text = page.extract_text()\n",
    "            if text and len(text.strip()) > 10:\n",
    "                return False  # Text-based PDF\n",
    "    return True  # Scanned PDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de905173-3bf1-4648-855c-f72c42ceb85e",
   "metadata": {},
   "source": [
    "#### _Testing_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35e19a96-93d1-4c5d-982f-694257072230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanned PDF: False\n"
     ]
    }
   ],
   "source": [
    "pdf_path = \"Ledger_Entries.pdf\"\n",
    "print(\"Scanned PDF:\", is_scanned_pdf(pdf_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f252a64-c416-426a-945e-92c69c6fd939",
   "metadata": {},
   "source": [
    "#### Extract Text Based on PDF Type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5487ff9-de15-42af-9461-e83b8fe44699",
   "metadata": {},
   "source": [
    "##### For Text-Based PDFs (Structured PDFs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1395ee6b-f2ee-4def-8b74-9108ca9d4aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"Extract text from structured PDFs using pdfplumber\"\"\"\n",
    "    text_data = []\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            text_data.append(page.extract_text())\n",
    "    return \"\\n\".join(text_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3577f91-ca41-490a-9cf7-1c7950458caa",
   "metadata": {},
   "source": [
    "##### For Scanned PDFs (OCR-Based Extraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e57852e1-c703-43e4-a334-cd692625e427",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pytesseract\n",
    "\n",
    "def extract_text_from_scanned_pdf(pdf_path):\n",
    "    \"\"\"Extract text from scanned PDFs using OCR\"\"\"\n",
    "    text_data = []\n",
    "    doc = fitz.open(pdf_path)\n",
    "\n",
    "    for page_num in range(len(doc)):\n",
    "        img = doc[page_num].get_pixmap()  # Convert to image\n",
    "        img_array = np.frombuffer(img.samples, dtype=np.uint8).reshape(img.height, img.width, 3)\n",
    "        gray = cv2.cvtColor(img_array, cv2.COLOR_BGR2GRAY)  # Convert to grayscale\n",
    "        text = pytesseract.image_to_string(gray)\n",
    "        text_data.append(text)\n",
    "    \n",
    "    return \"\\n\".join(text_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea039abb-b564-4482-b461-bfaf85963ce8",
   "metadata": {},
   "source": [
    "#### _Testing_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a12b3bc1-60bd-42a0-8c76-2917c82b2b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JOURNAL, LEDGER,\n",
      "SUBSIDIARY BOOKS AND\n",
      "TRIAL BALANCE\n",
      "Prepared by Mrs.M.Janani\n",
      "Department of Commerce (International Business)\n",
      "Governement Arts College, Coimbatore – 18.\n",
      "Refernce: Financial Accounting\n",
      "Author: T.S.Reddy & Dr.A.Murthy\n",
      "Journal:\n",
      "1. Journalise the following transactions of M/s. Radha & Sons.\n",
      "1.1.2000 Business Started with Rs.2,50,000 and cash deposited with Bank – 1,50,000\n",
      "3.1.2000 Purchasesd machinery on credit from Rangan – 50,000\n",
      "6.1.2000 Bought furniture from Ramesh for cash – 25,000\n",
      "12.1.2000 Goods sold to Yesodha – 22,500\n",
      "13.1.2000 Goods returned by Yesodha – 2,500\n",
      "15.1.2000 Goods sold for cash – 50,000\n",
      "17.1.2000 Bought goods for cash – 25,000\n",
      "20.1.2000 Cash received from Yesodha – 10,000\n",
      "21.1.2000 Cash paid to Ramola – 20,000\n",
      "25.1.2000 Cash withdrawn from bank – 50,000\n",
      "29.1.2000 Paid advertisement expenses – 12,500\n",
      "30.1.2000 Bought office stationery for cash – 5,000\n",
      "31.1.2000 Cash withdrawn from bank for personal use of the proprietor – 6,250\n",
      "31.1.2000 Paid salaries – \n"
     ]
    }
   ],
   "source": [
    "scanned = is_scanned_pdf(pdf_path)\n",
    "if scanned:\n",
    "    text = extract_text_from_scanned_pdf(pdf_path)\n",
    "else:\n",
    "    text = extract_text_from_pdf(pdf_path)\n",
    "\n",
    "print(text[:1000])  # Print first 1000 characters for verification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922f15d7-d6c6-48c0-b416-bfb4614d0572",
   "metadata": {},
   "source": [
    "#### Extract Financial Data (Ledger Entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2926ecb-8d78-4d2f-b796-b63ff473aeeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_ledger_entries(text):\n",
    "    \"\"\"Extract financial ledger entries using regex\"\"\"\n",
    "    pattern = re.compile(\n",
    "        r'(\\d{1,4}[-/.]\\d{1,2}[-/.]\\d{2,4})\\s+([\\w\\s]+?)\\s+(-?\\d{1,3}(?:,\\d{3})*(?:\\.\\d{2})?)\\s+(-?\\d{1,3}(?:,\\d{3})*(?:\\.\\d{2})?)'\n",
    "    )\n",
    "    transactions = []\n",
    "\n",
    "    for match in pattern.findall(text):\n",
    "        date, description, amount, balance = match\n",
    "        transactions.append({\n",
    "            \"Date\": date,\n",
    "            \"Description\": description.strip(),\n",
    "            \"Amount\": float(amount.replace(\",\", \"\")),  # Remove commas before conversion\n",
    "            \"Balance\": float(balance.replace(\",\", \"\"))  # Remove commas before conversion\n",
    "        })\n",
    "\n",
    "    return transactions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78076dc6-8f9c-4f4d-bb0f-7acf97191fe3",
   "metadata": {},
   "source": [
    "#### _Testing_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "216efc70-1af0-4613-ac56-2b4750a9eb42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Date': '1.4.2000', 'Description': 'To Sales', 'Amount': 6000.0, 'Balance': 5.0}, {'Date': '18.4.2000', 'Description': 'To Sales By Discount allowed', 'Amount': 200.0, 'Balance': 8000.0}, {'Date': '30.4.2000', 'Description': 'By Cash', 'Amount': 4500.0, 'Balance': 30.0}, {'Date': '22.5.2000', 'Description': 'By Cash', 'Amount': 4850.0, 'Balance': 12.0}, {'Date': '30.8.1987', 'Description': 'Returned inferior goods to Sankar', 'Amount': -800.0, 'Balance': 31.0}]\n"
     ]
    }
   ],
   "source": [
    "transactions = extract_ledger_entries(text)\n",
    "print(transactions[:5])  # Print first 5 transactions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5788aa9c-774d-48a2-be31-dfba920dc24c",
   "metadata": {},
   "source": [
    "#### Save Data to CSV/Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9e178137-2f8c-47da-8c95-13784db0672b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def save_to_csv(transactions, output_file):\n",
    "    \"\"\"Save extracted data to CSV\"\"\"\n",
    "    df = pd.DataFrame(transactions)\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"Data saved to {output_file}\")\n",
    "\n",
    "def save_to_excel(transactions, output_file):\n",
    "    \"\"\"Save extracted data to Excel\"\"\"\n",
    "    df = pd.DataFrame(transactions)\n",
    "    df.to_excel(output_file,index=False, engine='openpyxl')\n",
    "    print(f\"Data saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4fed796-8124-4efc-8d42-7bccd08965e8",
   "metadata": {},
   "source": [
    "#### Combine Everything in One Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c62597db-519f-4f91-8908-d28a23c6a34f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing structured PDF...\n",
      "Data saved to extracted_data.csv\n",
      "Data saved to extracted_data.xlsx\n"
     ]
    }
   ],
   "source": [
    "def process_pdf(pdf_path, output_file):\n",
    "    \"\"\"Main function to process PDF and extract structured financial data\"\"\"\n",
    "    scanned = is_scanned_pdf(pdf_path)\n",
    "\n",
    "    if scanned:\n",
    "        print(\"Processing scanned PDF with OCR...\")\n",
    "        extracted_text = extract_text_from_scanned_pdf(pdf_path)\n",
    "    else:\n",
    "        print(\"Processing structured PDF...\")\n",
    "        extracted_text = extract_text_from_pdf(pdf_path)\n",
    "\n",
    "    transactions = extract_ledger_entries(extracted_text)\n",
    "\n",
    "    if transactions:\n",
    "        save_to_csv(transactions, output_file.replace(\".xlsx\", \".csv\"))\n",
    "        save_to_excel(transactions, output_file)\n",
    "    else:\n",
    "        print(\"No financial data found in the document.\")\n",
    "\n",
    "# Run the complete pipeline\n",
    "pdf_file = \"Ledger_Entries.pdf\"  # Change this to your PDF file\n",
    "output_file = \"extracted_data.xlsx\"\n",
    "process_pdf(pdf_file, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee619a6-a37d-41a2-ac2b-38e1860d8cae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
